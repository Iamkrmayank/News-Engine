#!/usr/bin/env python3
"""
Manager ko Convince Karne ke Liye - Simple FastAPI vs n8n Comparison
"""
import requests
import time
import json
from concurrent.futures import ThreadPoolExecutor
import threading

BASE_URL = "http://localhost:8000"

def test_simple_endpoint():
    """Simple endpoint test"""
    try:
        start_time = time.time()
        response = requests.get(f"{BASE_URL}/", timeout=10)
        end_time = time.time()
        
        return {
            "status": response.status_code,
            "response_time": end_time - start_time,
            "success": response.status_code == 200
        }
    except Exception as e:
        return {
            "status": 0,
            "response_time": 0,
            "success": False,
            "error": str(e)
        }

def simulate_n8n_request():
    """Simulate n8n workflow execution"""
    # n8n typical execution time: 100-300ms per workflow
    time.sleep(0.2)  # 200ms simulation
    return {
        "status": 200,
        "response_time": 0.2,
        "success": True
    }

def run_fastapi_test(num_requests=100):
    """Run FastAPI concurrent test"""
    print(f"üöÄ FastAPI Test: {num_requests} concurrent requests")
    
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=50) as executor:
        futures = [executor.submit(test_simple_endpoint) for _ in range(num_requests)]
        results = [future.result() for future in futures]
    
    end_time = time.time()
    total_time = end_time - start_time
    
    successful = sum(1 for r in results if r["success"])
    avg_response_time = sum(r["response_time"] for r in results if r["success"]) / max(successful, 1)
    rps = num_requests / total_time
    
    print(f"‚úÖ Successful: {successful}/{num_requests}")
    print(f"‚è±Ô∏è  Total time: {total_time:.2f}s")
    print(f"üöÄ Requests/sec: {rps:.2f}")
    print(f"üìä Avg response: {avg_response_time:.3f}s")
    
    return {
        "requests_per_second": rps,
        "avg_response_time": avg_response_time,
        "success_rate": successful/num_requests*100
    }

def run_n8n_simulation(num_requests=100):
    """Run n8n simulation"""
    print(f"\nüîÑ n8n Simulation: {num_requests} workflows")
    
    start_time = time.time()
    
    # n8n typically limits concurrent executions
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(simulate_n8n_request) for _ in range(num_requests)]
        results = [future.result() for future in futures]
    
    end_time = time.time()
    total_time = end_time - start_time
    
    successful = sum(1 for r in results if r["success"])
    avg_response_time = sum(r["response_time"] for r in results) / len(results)
    rps = num_requests / total_time
    
    print(f"‚úÖ Successful: {successful}/{num_requests}")
    print(f"‚è±Ô∏è  Total time: {total_time:.2f}s")
    print(f"üöÄ Workflows/sec: {rps:.2f}")
    print(f"üìä Avg execution: {avg_response_time:.3f}s")
    
    return {
        "requests_per_second": rps,
        "avg_response_time": avg_response_time,
        "success_rate": successful/num_requests*100
    }

def main():
    """Main comparison function"""
    print("üî• FastAPI vs n8n - Manager Convincing Test")
    print("="*60)
    
    # Test configurations
    test_sizes = [50, 100, 200]
    
    for size in test_sizes:
        print(f"\nüìä Test Size: {size} requests")
        print("-" * 40)
        
        try:
            # Test FastAPI
            fastapi_results = run_fastapi_test(size)
            
            # Test n8n simulation
            n8n_results = run_n8n_simulation(size)
            
            # Calculate improvement
            improvement = ((fastapi_results["requests_per_second"] - n8n_results["requests_per_second"]) / n8n_results["requests_per_second"]) * 100
            
            print(f"\nüèÜ RESULTS COMPARISON:")
            print(f"FastAPI: {fastapi_results['requests_per_second']:.1f} req/sec")
            print(f"n8n: {n8n_results['requests_per_second']:.1f} workflows/sec")
            
            if improvement > 0:
                print(f"‚úÖ FastAPI is {improvement:.1f}% FASTER!")
            else:
                print(f"‚ùå n8n is {abs(improvement):.1f}% faster")
            
            print(f"\nüí° KEY POINTS:")
            print(f"‚Ä¢ FastAPI handles {fastapi_results['requests_per_second']:.0f} requests per second")
            print(f"‚Ä¢ n8n handles {n8n_results['requests_per_second']:.0f} workflows per second")
            print(f"‚Ä¢ FastAPI response time: {fastapi_results['avg_response_time']:.3f}s")
            print(f"‚Ä¢ n8n execution time: {n8n_results['avg_response_time']:.3f}s")
            
        except Exception as e:
            print(f"‚ùå Test failed: {e}")
        
        print("\n" + "="*60)
    
    print(f"\nüéØ FINAL RECOMMENDATION:")
    print(f"FastAPI is BETTER for:")
    print(f"‚Ä¢ High-concurrency APIs")
    print(f"‚Ä¢ Real-time applications") 
    print(f"‚Ä¢ Microservices")
    print(f"‚Ä¢ Production APIs")
    print(f"\nn8n is BETTER for:")
    print(f"‚Ä¢ Workflow automation")
    print(f"‚Ä¢ Data integration")
    print(f"‚Ä¢ Non-technical users")
    print(f"‚Ä¢ Scheduled tasks")

if __name__ == "__main__":
    main()
